# Comment Toxicity Classifier

## Overview

The Comment Toxicity Classifier is a deep learning-based application created using Gradio to classify comments into six categories: toxic, severely toxic, obscene, threat, insult, and hate based on identity. This tool is designed to analyze and categorize comments, helping to identify and manage potentially harmful content in online discussions.

## Features

- **Deep Learning Model:** The classifier employs a robust deep learning model trained on a diverse dataset to accurately categorize comments into different toxicity levels.

- **Six Categories:** The classifier classifies comments into the following six categories:
  - Toxic
  - Severely Toxic
  - Obscene
  - Threat
  - Insult
  - Hate Based on Identity

- **Gradio Interface:** The application utilizes Gradio to create a user-friendly interface for interacting with the classifier. Gradio allows users to input comments and receive real-time toxicity predictions.

## Getting Started

Follow these steps to get started with the Comment Toxicity Classifier:

1. **Install Dependencies:**
   ```bash
   pip install -r requirements.txt

